{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee el archivo CSV con todos los datos. Para esto, se utiliza la función loadtxt del paquete NumPY.  \n",
    "Luego se separan las filas en dos listas con el fin de tener las variables separadas de la variable objetivo.  \n",
    "Por último se realiza un escalado de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "# Lectura\n",
    "dataset=np.loadtxt(\"cars.csv\", delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Separación\n",
    "x=dataset[:,0:5]\n",
    "y=dataset[:,5]\n",
    "y=np.reshape(y, (-1,1))\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(x)\n",
    "xscale=scaler_x.transform(x)\n",
    "scaler_y.fit(y)\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se separan los datos en datos de entrenamiento y datos de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un modelo de red neuronal muy básico que consiste de:\n",
    "    * Una capa de 12 neuronas con función de activación ReLU\n",
    "    * Una capa de 8 neuronas con función de activación ReLU\n",
    "    * Una capa de 1 neurona con función de activación Linear (Es decir, sin activación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model [(5), 12, 8, 1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compila el modelo para poder ser entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se entrena el modelo con los parametros elegidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1769 - mse: 0.1769 - mae: 0.3127 - val_loss: 0.1304 - val_mse: 0.1304 - val_mae: 0.2663\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1014 - mse: 0.1014 - mae: 0.2382 - val_loss: 0.0789 - val_mse: 0.0789 - val_mae: 0.2228\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0687 - mse: 0.0687 - mae: 0.2156 - val_loss: 0.0586 - val_mse: 0.0586 - val_mae: 0.2088\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - mae: 0.2086 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.2025\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.2037 - val_loss: 0.0493 - val_mse: 0.0493 - val_mae: 0.1953\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1946 - val_loss: 0.0462 - val_mse: 0.0462 - val_mae: 0.1873\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448 - mae: 0.1851 - val_loss: 0.0432 - val_mse: 0.0432 - val_mae: 0.1798\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1764 - val_loss: 0.0402 - val_mse: 0.0402 - val_mae: 0.1718\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - mae: 0.1676 - val_loss: 0.0373 - val_mse: 0.0373 - val_mae: 0.1640\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335 - mae: 0.1584 - val_loss: 0.0347 - val_mse: 0.0347 - val_mae: 0.1569\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0303 - mae: 0.1495 - val_loss: 0.0321 - val_mse: 0.0321 - val_mae: 0.1492\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - mae: 0.1399 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1416\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - mae: 0.1304 - val_loss: 0.0278 - val_mse: 0.0278 - val_mae: 0.1343\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.1223 - val_loss: 0.0260 - val_mse: 0.0260 - val_mae: 0.1274\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1141 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1188\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.1054 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1117\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.1010 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1089\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0964 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1068\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0932 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1063\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0926 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1061\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0940 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1058\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0921 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1054\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0923 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1054\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0922 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1053\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0912 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1051\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0919 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1053\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0913 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.1047\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0911 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1046\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0905 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.1043\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0901 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1042\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0898 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1041\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0895 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1039\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0894 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1040\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0889 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1034\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0893 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1033\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0885 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1031\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0881 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1032\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0885 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1027\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0878 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1025\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0875 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1024\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0875 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1024\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0876 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1017\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0868 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1013\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0873 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1010\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0863 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1008\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0865 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1006\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0870 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1006\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0860 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1002\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0857 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.1006\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0869 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0997\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0861 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0999\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0853 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0996\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0851 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1000\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0860 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0994\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0851 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0996\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0851 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0990\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0855 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.0991\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0842 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0992\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0850 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.0993\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0854 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0984\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0852 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0992\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0840 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0984\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0865 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0985\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0838 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0986\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0843 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0986\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0845 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0984\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0834 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0993\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0846 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0981\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0838 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0978\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0838 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0977\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0830 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0980\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0840 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0974\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0831 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0982\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0833 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0972\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0841 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0975\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0839 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0974\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0825 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0972\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0834 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0969\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0823 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0971\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0822 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0974\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0829 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0970\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0820 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0972\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0819 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0971\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0835 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0965\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0815 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0978\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0831 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0965\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0818 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0974\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0826 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0968\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0829 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0963\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0814 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0963\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0814 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0964\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0822 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0965\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0809 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0963\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0820 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0957\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0820 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0961\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0813 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0958\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0814 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0960\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0808 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0966\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0814 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0959\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0807 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0962\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0802 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0956\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0825 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0950\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0804 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0971\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0819 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0953\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0806 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0955\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0804 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0950\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0813 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0967\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0811 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0951\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0814 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0950\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0803 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0956\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0802 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0961\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0816 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0946\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0820 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0945\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0802 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0953\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0805 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0946\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0802 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0966\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0808 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0942\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0796 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0957\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0806 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0944\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0799 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0950\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0801 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0942\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0793 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0942\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0797 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0939\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0797 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0945\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0792 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0940\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0798 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0944\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0793 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0938\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0794 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0939\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0798 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0936\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0788 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0947\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0804 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0937\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0808 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0937\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0789 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0936\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0795 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0934\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0794 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0932\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0794 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0934\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0791 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0940\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0786 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0933\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0786 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0941\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0788 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0941\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0798 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0934\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0789 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0934\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0781 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0936\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0781 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0939\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0786 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0929\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0786 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0930\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0781 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0931\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0782 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0937\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0782 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0931\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0782 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0934\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se visualiza la gráfica de función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una predicción del modelo entrenado para probrar nuestro modelo con un nuevo dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[  40.    0.   26. 9000. 8000.], Predicted=[14143.134]\n"
     ]
    }
   ],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])\n",
    "Xnew= scaler_x.transform(Xnew)\n",
    "ynew= model.predict(Xnew)\n",
    "#invert normalize\n",
    "ynew = scaler_y.inverse_transform(ynew) \n",
    "Xnew = scaler_x.inverse_transform(Xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
